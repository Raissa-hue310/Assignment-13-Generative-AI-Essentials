{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiVgAd82z/BWik6IXDN27w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raissa-hue310/Assignment-13-Generative-AI-Essentials/blob/main/Assignment13_Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 13: Generative AI Essentials\n",
        "Shakespeare Text Generation - By Raïssa Matho Mekjele"
      ],
      "metadata": {
        "id": "Vl40ponBFr8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QpEhkdcXCa0z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1. LOAD DATA\n",
        "# -----------------------------\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "text = requests.get(url).text\n",
        "\n",
        "print(\"Sample text:\")\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fAk5ji0GLDi",
        "outputId": "ef6e95f4-7ac6-4b2e-8804-7f6b53b7b1b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample text:\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 2. CHAR-LEVEL TOKENIZATION\n",
        "# -----------------------------\n",
        "tokenizer = Tokenizer(char_level=True, filters='')\n",
        "tokenizer.fit_on_texts([text])\n",
        "\n",
        "total_chars = len(tokenizer.word_index) + 1\n",
        "print(\"Total unique characters:\", total_chars)\n",
        "\n",
        "# Convert full dataset into sequences safely\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezzmY1TMGQ8Q",
        "outputId": "1ac829f8-8b3a-4775-a69e-af3d8a06ccaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique characters: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 3. SEQUENCE GENERATION\n",
        "# -----------------------------\n",
        "sequence_length = 40\n",
        "\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(len(encoded) - sequence_length):\n",
        "    sequences.append(encoded[i:i+sequence_length])\n",
        "    next_chars.append(encoded[i+sequence_length])\n",
        "\n",
        "X = np.array(sequences)\n",
        "y = tf.keras.utils.to_categorical(next_chars, num_classes=total_chars)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srThAO0zHklS",
        "outputId": "7ca6c899-2b81-49df-85f6-83f938f9183f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1115354, 40)\n",
            "y shape: (1115354, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4. BUILD MODEL\n",
        "# -----------------------------\n",
        "model = Sequential([\n",
        "    Embedding(total_chars, 64, input_length=sequence_length),\n",
        "    LSTM(128),\n",
        "    Dense(total_chars, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "-ETYavmPHz4K",
        "outputId": "e563c02a-cb62-4743-d282-0cdf6f1c1c33"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 5. TRAIN MODEL\n",
        "# -----------------------------\n",
        "history = model.fit(X, y, epochs=3, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nR1vIfUH6AZ",
        "outputId": "2852de3f-b34b-41cd-b6dd-848abf9d8d53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m8714/8714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1103s\u001b[0m 126ms/step - accuracy: 0.3697 - loss: 2.1632\n",
            "Epoch 2/3\n",
            "\u001b[1m8714/8714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 125ms/step - accuracy: 0.5122 - loss: 1.6123\n",
            "Epoch 3/3\n",
            "\u001b[1m8714/8714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1085s\u001b[0m 124ms/step - accuracy: 0.5377 - loss: 1.5115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 6. TEXT GENERATION FUNCTION\n",
        "# -----------------------------\n",
        "reverse_index = {v: k for k, v in tokenizer.word_index.items()}\n",
        "\n",
        "def generate_text(seed, length=300):\n",
        "    generated = seed\n",
        "\n",
        "    for _ in range(length):\n",
        "        encoded_seed = tokenizer.texts_to_sequences([seed[-sequence_length:]])[0]\n",
        "        encoded_seed = pad_sequences([encoded_seed], maxlen=sequence_length)\n",
        "\n",
        "        predictions = model.predict(encoded_seed, verbose=0)\n",
        "        next_index = np.argmax(predictions)\n",
        "        next_char = reverse_index.get(next_index, \"\")\n",
        "\n",
        "        generated += next_char\n",
        "        seed += next_char\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "JHGjb_xTUfVh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 7. GENERATE SAMPLE TEXT\n",
        "# -----------------------------\n",
        "seed_text = \"ROMEO: My love is like the sun\"\n",
        "generated_sample = generate_text(seed_text, 400)\n",
        "\n",
        "print(\"\\nGenerated Text:\\n\")\n",
        "print(generated_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3h3BVb7UuVz",
        "outputId": "7eb92aa1-06db-4c96-ec94-2a13def4214b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Text:\n",
            "\n",
            "ROMEO: My love is like the sun\n",
            "that i will be the strike and the strike.\n",
            "\n",
            "prospero:\n",
            "what shall be the sently to the sun and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the se\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 8. APPLICATION DEMO\n",
        "# -----------------------------\n",
        "def style_rewriter(input_text):\n",
        "    seed = input_text[:40]\n",
        "    return generate_text(seed, 250)\n",
        "\n",
        "demo_output = style_rewriter(\"I dream of building a better future for all.\")\n",
        "print(\"\\nDemo Application Output:\\n\")\n",
        "print(demo_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpBWy3tTU8oA",
        "outputId": "5c220144-2381-4045-b69e-a56bde6ba185"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Demo Application Output:\n",
            "\n",
            "I dream of building a better future for the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle and the sentle\n"
          ]
        }
      ]
    }
  ]
}